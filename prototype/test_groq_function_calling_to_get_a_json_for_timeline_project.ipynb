{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R5OJcxINYeh",
        "outputId": "37d85a75-950e-4540-8f0e-49a9d0496166"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.20.0)\n",
            "Installing collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make JSON function call"
      ],
      "metadata": {
        "id": "VKH_10lKNtZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### default example"
      ],
      "metadata": {
        "id": "rV-hSsjMNvSu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn_HSgeONW3_",
        "outputId": "3496ae2d-e5a4-4d48-acbb-361485e5e30c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score of the Warriors game was 128-121, where the Golden State Warriors defeated the Los Angeles Lakers.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "from groq import Groq\n",
        "import os\n",
        "import json\n",
        "\n",
        "client = Groq(api_key = userdata.get('GROQ_API_KEY'))\n",
        "MODEL = 'llama3-70b-8192'\n",
        "\n",
        "\n",
        "# Example dummy function hard coded to return the score of an NBA game\n",
        "def get_game_score(team_name):\n",
        "    \"\"\"Get the current score for a given NBA game\"\"\"\n",
        "    if \"warriors\" in team_name.lower():\n",
        "        return json.dumps({\"game_id\": \"401585601\", \"status\": 'Final', \"home_team\": \"Los Angeles Lakers\", \"home_team_score\": 121, \"away_team\": \"Golden State Warriors\", \"away_team_score\": 128})\n",
        "    elif \"lakers\" in team_name.lower():\n",
        "        return json.dumps({\"game_id\": \"401585601\", \"status\": 'Final', \"home_team\": \"Los Angeles Lakers\", \"home_team_score\": 121, \"away_team\": \"Golden State Warriors\", \"away_team_score\": 128})\n",
        "    elif \"nuggets\" in team_name.lower():\n",
        "        return json.dumps({\"game_id\": \"401585577\", \"status\": 'Final', \"home_team\": \"Miami Heat\", \"home_team_score\": 88, \"away_team\": \"Denver Nuggets\", \"away_team_score\": 100})\n",
        "    elif \"heat\" in team_name.lower():\n",
        "        return json.dumps({\"game_id\": \"401585577\", \"status\": 'Final', \"home_team\": \"Miami Heat\", \"home_team_score\": 88, \"away_team\": \"Denver Nuggets\", \"away_team_score\": 100})\n",
        "    else:\n",
        "        return json.dumps({\"team_name\": team_name, \"score\": \"unknown\"})\n",
        "\n",
        "def run_conversation(user_prompt):\n",
        "    # Step 1: send the conversation and available functions to the model\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a function calling LLM that uses the data extracted from the get_game_score function to answer questions around NBA game scores. Include the team and their opponent in your response.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_prompt,\n",
        "        }\n",
        "    ]\n",
        "    tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"get_game_score\",\n",
        "                \"description\": \"Get the score for a given NBA game\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"team_name\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The name of the NBA team (e.g. 'Golden State Warriors')\",\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"team_name\"],\n",
        "                },\n",
        "            },\n",
        "        }\n",
        "    ]\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "        max_tokens=4096\n",
        "    )\n",
        "\n",
        "    response_message = response.choices[0].message\n",
        "    tool_calls = response_message.tool_calls\n",
        "    # Step 2: check if the model wanted to call a function\n",
        "    if tool_calls:\n",
        "        # Step 3: call the function\n",
        "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
        "        available_functions = {\n",
        "            \"get_game_score\": get_game_score,\n",
        "        }  # only one function in this example, but you can have multiple\n",
        "        messages.append(response_message)  # extend conversation with assistant's reply\n",
        "        # Step 4: send the info for each function call and function response to the model\n",
        "        for tool_call in tool_calls:\n",
        "            function_name = tool_call.function.name\n",
        "            function_to_call = available_functions[function_name]\n",
        "            function_args = json.loads(tool_call.function.arguments)\n",
        "            function_response = function_to_call(\n",
        "                team_name=function_args.get(\"team_name\")\n",
        "            )\n",
        "            messages.append(\n",
        "                {\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"role\": \"tool\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response,\n",
        "                }\n",
        "            )  # extend conversation with function response\n",
        "        second_response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages\n",
        "        )  # get a new response from the model where it can see the function response\n",
        "        return second_response.choices[0].message.content\n",
        "\n",
        "user_prompt = \"What was the score of the Warriors game?\"\n",
        "print(run_conversation(user_prompt))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Timeline function  \n",
        "\n",
        "We use Pydantic to define the model, and check the LLM json for validity.  "
      ],
      "metadata": {
        "id": "k3bYD-jvNxE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from groq import Groq\n",
        "from pydantic import BaseModel, ValidationError, Field\n",
        "from typing import List\n",
        "import os\n",
        "import json\n",
        "\n",
        "client = Groq(api_key=userdata.get('GROQ_API_KEY'))\n",
        "MODEL = 'llama3-70b-8192'\n",
        "\n",
        "class TimelineEvent(BaseModel):\n",
        "    timestamp: str = Field(..., description=\"Date of the event\")\n",
        "    title: str = Field(..., description=\"Title of the event\")\n",
        "    description: str = Field(..., description=\"Short description of the event\")\n",
        "\n",
        "class Timeline(BaseModel):\n",
        "    timeline: List[TimelineEvent]\n",
        "\n",
        "# Example dummy function hard coded to return the score of an NBA game\n",
        "def save_timeline(timeline_data):\n",
        "    try:\n",
        "        timeline = Timeline(**timeline_data)\n",
        "        return timeline\n",
        "    except ValidationError as e:\n",
        "        return {\"error\": e.errors()}\n",
        "\n",
        "def run_conversation(user_prompt):\n",
        "    # Step 1: send the conversation and available functions to the model\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a function calling LLM that saves timelines using the function save_timeline. When prompted to give the timeline for an event, save it using the save_timeline function.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_prompt,\n",
        "        }\n",
        "    ]\n",
        "    tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"name\": \"save_timeline\",\n",
        "            \"description\": \"Save a timeline to database.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"timeline\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"timestamp\": {\n",
        "                                    \"type\": \"string\",\n",
        "                                    \"description\": \"date of the event\"\n",
        "                                },\n",
        "                                \"title\": {\n",
        "                                    \"type\": \"string\",\n",
        "                                    \"description\": \"title of the event\"\n",
        "                                },\n",
        "                                \"description\": {\n",
        "                                    \"type\": \"string\",\n",
        "                                    \"description\": \"short description of the event\"\n",
        "                                }\n",
        "                            },\n",
        "                            \"required\": [\"timestamp\", \"title\", \"description\"]\n",
        "                        }\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"timeline\"]\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        functions=tools,\n",
        "        max_tokens=4096\n",
        "    )\n",
        "\n",
        "    try:\n",
        "      response_message = response.choices[0].message\n",
        "      timeline_data = json.loads(response_message.function_call.arguments)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      return response\n",
        "\n",
        "    try:\n",
        "      result = save_timeline(timeline_data)\n",
        "      return result\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      return response\n",
        "\n",
        "    return response\n",
        "\n",
        "# Example usage\n",
        "user_prompt = \"Provide a timeline for the events of September 11, 2001.\"\n",
        "result = run_conversation(user_prompt)\n",
        "print(json.dumps(json.loads(result.json()), indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3CSztNVSI-D",
        "outputId": "8a0c3f69-1963-4a79-acae-778c87603a98"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"timeline\": [\n",
            "    {\n",
            "      \"timestamp\": \"2001-09-11 07:59:00\",\n",
            "      \"title\": \"Flight 11 Departs\",\n",
            "      \"description\": \"American Airlines Flight 11 takes off from Boston's Logan International Airport\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"2001-09-11 08:14:00\",\n",
            "      \"title\": \"Flight 175 Departs\",\n",
            "      \"description\": \"United Airlines Flight 175 takes off from Boston's Logan International Airport\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"2001-09-11 08:20:00\",\n",
            "      \"title\": \"Flight 77 Departs\",\n",
            "      \"description\": \"American Airlines Flight 77 takes off from Washington Dulles International Airport\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"2001-09-11 08:42:00\",\n",
            "      \"title\": \"Flight 93 Departs\",\n",
            "      \"description\": \"United Airlines Flight 93 takes off from Newark International Airport\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"2001-09-11 08:46:00\",\n",
            "      \"title\": \"Flight 11 Crashes into North Tower\",\n",
            "      \"description\": \"American Airlines Flight 11 crashes into the North Tower of the World Trade Center\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"2001-09-11 09:03:00\",\n",
            "      \"title\": \"Flight 175 Crashes into South Tower\",\n",
            "      \"description\": \"United Airlines Flight 175 crashes into the South Tower of the World Trade Center\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"2001-09-11 09:37:00\",\n",
            "      \"title\": \"Flight 77 Crashes into Pentagon\",\n",
            "      \"description\": \"American Airlines Flight 77 crashes into the Pentagon\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"2001-09-11 10:03:00\",\n",
            "      \"title\": \"Flight 93 Crashes in Pennsylvania\",\n",
            "      \"description\": \"United Airlines Flight 93 crashes into a field in Shanksville, Pennsylvania\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"2001-09-11 09:59:00\",\n",
            "      \"title\": \"South Tower Collapses\",\n",
            "      \"description\": \"The South Tower of the World Trade Center collapses\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"2001-09-11 10:28:00\",\n",
            "      \"title\": \"North Tower Collapses\",\n",
            "      \"description\": \"The North Tower of the World Trade Center collapses\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make two successful test and one error test  \n",
        "\n",
        "We want to see if this functions works for different applications, and what happens when the LLM doesn't serve a Timeline object."
      ],
      "metadata": {
        "id": "6V7ctyGCWK9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"Provide a timeline for the flie of Napoleon Bonaparte\"\n",
        "result = run_conversation(user_prompt)\n",
        "print(json.dumps(json.loads(result.json()), indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbOYt6D8SnP0",
        "outputId": "3109fdad-d1c1-40dc-c006-6689cec99a1e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"timeline\": [\n",
            "    {\n",
            "      \"timestamp\": \"1769-08-15\",\n",
            "      \"title\": \"Birth\",\n",
            "      \"description\": \"Napoleon was born\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"1785-10-28\",\n",
            "      \"title\": \"Education\",\n",
            "      \"description\": \"Napoleon graduated from \\u00c9cole Militaire\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"1793-07-07\",\n",
            "      \"title\": \"Rise to Power\",\n",
            "      \"description\": \"Napoleon became a general\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"1799-11-09\",\n",
            "      \"title\": \"Coup d'\\u00e9tat\",\n",
            "      \"description\": \"Napoleon overthrew the French Directory\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"1804-12-02\",\n",
            "      \"title\": \"Coronation\",\n",
            "      \"description\": \"Napoleon was crowned Emperor of France\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"1813-10-16\",\n",
            "      \"title\": \"Defeat\",\n",
            "      \"description\": \"Napoleon defeated at the Battle of Leipzig\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"1814-04-06\",\n",
            "      \"title\": \"Exile\",\n",
            "      \"description\": \"Napoleon exiled to Elba\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"1815-02-26\",\n",
            "      \"title\": \"Escape\",\n",
            "      \"description\": \"Napoleon escaped from Elba\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"1815-06-18\",\n",
            "      \"title\": \"Final Defeat\",\n",
            "      \"description\": \"Napoleon defeated at the Battle of Waterloo\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"1821-05-05\",\n",
            "      \"title\": \"Death\",\n",
            "      \"description\": \"Napoleon died\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"Provide a timeline for an apple pie recipe\"\n",
        "result = run_conversation(user_prompt)\n",
        "print(json.dumps(json.loads(result.json()), indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gowsvWDqTok6",
        "outputId": "365a17bc-c9d0-44bc-b60d-4633109cfd40"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"timeline\": [\n",
            "    {\n",
            "      \"timestamp\": \"12:00 pm\",\n",
            "      \"title\": \"Preheat oven\",\n",
            "      \"description\": \"Preheat oven to 375\\u00b0F (190\\u00b0C)\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"12:15 pm\",\n",
            "      \"title\": \"Make pie crust\",\n",
            "      \"description\": \"Make the pie crust\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"12:30 pm\",\n",
            "      \"title\": \"Prepare apple filling\",\n",
            "      \"description\": \"Prepare the apple filling\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"12:45 pm\",\n",
            "      \"title\": \"Assemble pie\",\n",
            "      \"description\": \"Assemble the pie\"\n",
            "    },\n",
            "    {\n",
            "      \"timestamp\": \"1:00 pm\",\n",
            "      \"title\": \"Bake pie\",\n",
            "      \"description\": \"Bake the pie for 45-50 minutes\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"What is the capital of France?\"\n",
        "result = run_conversation(user_prompt)\n",
        "print(json.dumps(json.loads(result.json()), indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0PQDJ_UVwCe",
        "outputId": "4673529d-cef2-4b3f-9b18-37fc002eceb7"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'NoneType' object has no attribute 'arguments'\n",
            "{\n",
            "  \"id\": \"chatcmpl-2532e054-643f-4b7c-8397-bfc298f46c5e\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"The capital of France is Paris.\",\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": null\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1720190527,\n",
            "  \"model\": \"llama3-70b-8192\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"system_fingerprint\": \"fp_753a4aecf6\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 8,\n",
            "    \"prompt_tokens\": 1066,\n",
            "    \"total_tokens\": 1074,\n",
            "    \"completion_time\": 0.022857143,\n",
            "    \"prompt_time\": 0.292474678,\n",
            "    \"queue_time\": null,\n",
            "    \"total_time\": 0.315331821\n",
            "  },\n",
            "  \"x_groq\": {\n",
            "    \"id\": \"req_01j21ngt4sfr3tgc9yfq2jrev6\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VBmDVqfmWGck"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}